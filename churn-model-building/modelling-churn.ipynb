{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec89623a-465b-4a81-9930-9e1b5339ed1b",
   "metadata": {},
   "source": [
    "# Churn Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b183de-19da-428e-9696-a05a80b993e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa064625-05c9-4a3d-8245-673e4051003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==2.3.1\n",
      "numpy==2.3.1\n",
      "sklearn==1.7.0\n"
     ]
    }
   ],
   "source": [
    "print(f'pandas=={pd.__version__}')\n",
    "print(f'numpy=={np.__version__}')\n",
    "print(f'sklearn=={sklearn.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c401429a-4a08-4c56-8db9-574167cd4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split               # --> data splitting\n",
    "from sklearn.model_selection import KFold                           # --> create folds\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer             # --> handle categorical variables\n",
    "from sklearn.linear_model import LogisticRegression               # --> logistic model\n",
    "from sklearn.metrics import roc_auc_score                         # --> evaluate with auc_roc_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c3fb22-e935-4b3e-a5f4-bb84d6db541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-03 19:22:54--  https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/refs/heads/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 977501 (955K) [text/plain]\n",
      "Saving to: ‘WA_Fn-UseC_-Telco-Customer-Churn.csv’\n",
      "\n",
      "WA_Fn-UseC_-Telco-C 100%[===================>] 954.59K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-11-03 19:22:54 (132 MB/s) - ‘WA_Fn-UseC_-Telco-Customer-Churn.csv’ saved [977501/977501]\n",
      "\n",
      "customerid          0\n",
      "gender              0\n",
      "seniorcitizen       0\n",
      "partner             0\n",
      "dependents          0\n",
      "tenure              0\n",
      "phoneservice        0\n",
      "multiplelines       0\n",
      "internetservice     0\n",
      "onlinesecurity      0\n",
      "onlinebackup        0\n",
      "deviceprotection    0\n",
      "techsupport         0\n",
      "streamingtv         0\n",
      "streamingmovies     0\n",
      "contract            0\n",
      "paperlessbilling    0\n",
      "paymentmethod       0\n",
      "monthlycharges      0\n",
      "totalcharges        0\n",
      "churn               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/refs/heads/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv', na_values=['', ' '])\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "string_cols = list(df.dtypes[df.dtypes=='object'].index)\n",
    "\n",
    "for col in string_cols:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Replace missingness with in total charges with median value\n",
    "df['totalcharges'] = df['totalcharges'].fillna(df['totalcharges'].median())\n",
    "\n",
    "df.churn = (df.churn == 'yes').astype(int)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfc25be-05e6-4c42-9e57-0525f73e267f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5634, 21), (1409, 21))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2,random_state=1)\n",
    "df_full_train.shape, df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2349604f-cbeb-4e6d-a979-638e6bc27d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "categorical = [\n",
    "     'gender',\n",
    "     'seniorcitizen',\n",
    "     'partner',\n",
    "     'dependents',\n",
    "     'phoneservice',\n",
    "     'multiplelines',\n",
    "     'internetservice',\n",
    "     'onlinesecurity',\n",
    "     'onlinebackup',\n",
    "     'deviceprotection',\n",
    "     'techsupport',\n",
    "     'streamingtv',\n",
    "     'streamingmovies',\n",
    "     'contract',\n",
    "     'paperlessbilling',\n",
    "     'paymentmethod',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1529106e-865a-4bd4-aac8-3182ad256f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline - function that accepts X, y, C,\n",
    "# get the dictvectorizer on train, fit the logistic model, returns dv, model\n",
    "\n",
    "def train(df_train, y_train, C=0.5):\n",
    "    train_dicts = df_train[numerical + categorical].to_dict(orient = 'records')\n",
    "\n",
    "    dv = DictVectorizer(sparse = False)\n",
    "\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    model = LogisticRegression(C=0.5, max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73388786-893c-46b9-b4f4-fb5c391f4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "\n",
    "def predict(df_val, dv, model):\n",
    "    val_dicts = df_val[numerical + categorical].to_dict(orient = 'records')\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3388bfca-5c0f-4bf7-962c-492f5d64762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.5 0.842 +- 0.007\n"
     ]
    }
   ],
   "source": [
    "C = 0.5\n",
    "n_splits = 5\n",
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C) #--> the train function we wrote\n",
    "    y_pred = predict(df_val, dv, model)       #--> the predict function we wrote\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('C = %s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e41a41-1366-486f-bef8-5a979f5c764e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583490417844801"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=0.5)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "y_test = df_test.churn.values\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred); auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e91d1-4c0b-4622-afd3-45ca6927e375",
   "metadata": {},
   "source": [
    "# Save the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4c030f-77b2-4f37-99b0-d845cdcf3374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_C=0.5.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(C=0.5, max_iter=10000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "output_file = f'model_C={C}.bin'\n",
    "print(output_file)\n",
    "\n",
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump((dv, model), f_out)\n",
    "    #do stuff\n",
    "\n",
    "#do other stuff below\n",
    "dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a52008-4156-4092-9d06-98fbebd9425f",
   "metadata": {},
   "source": [
    "## Post Model Training \n",
    "## Load the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fef2751-d14d-4aeb-bae2-e24b9219f7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(C=0.5, max_iter=10000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_file = 'model_C=0.5.bin'\n",
    "\n",
    "with open(model_file, 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)\n",
    "    \n",
    "dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c959db2e-6bc3-4493-9ff7-eaeeaf61cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5624257721722079\n",
      "send email with promo\n"
     ]
    }
   ],
   "source": [
    "# df_test.shape\n",
    "\n",
    "test_customer = {\n",
    "    'gender': 'male',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'no',\n",
    "    'dependents': 'yes',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbiling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': (1 * 29.85)\n",
    "}\n",
    "\n",
    "X = dv.transform([test_customer])\n",
    "churn_proba = model.predict_proba(X)[0,1]\n",
    "print(churn_proba)\n",
    "\n",
    "if churn_proba >=0.5:\n",
    "    print('send email with promo')\n",
    "else:\n",
    "    print('Do not send promo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1d6bf-ba57-4e50-aaf6-746baa769a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c727ffb5-60fc-4162-bb19-2e60fbae7d5f",
   "metadata": {},
   "source": [
    "# Option 2 - Efficient Pipeline \n",
    "## Fit a final model with pipelines - feed the parameters from the CV done prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "decbb090-3061-4142-8ee5-e4403cd8c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_model_C=0.5.bin\n",
      "0.5624257721722079\n",
      "send email with promo\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "best_C = C\n",
    "\n",
    "training_pipeline = make_pipeline(\n",
    "    DictVectorizer(sparse = False),\n",
    "    LogisticRegression(C=best_C, max_iter=10000)    #solver='liblinear'\n",
    ")\n",
    "\n",
    "y_train = df_full_train.churn.values\n",
    "train_dict = df_full_train[categorical + numerical].to_dict(orient='records')\n",
    "training_pipeline.fit(train_dict, y_train)\n",
    "\n",
    "test_dict = df_test[Categorical + numerical].to_dict(orient = 'records')\n",
    "y_pred_pipe = training_pipeline.predict_proba(test_dict)[:,1]\n",
    "y_test = df_test.churn.values\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred_pipe)\n",
    "print('auc on held out test data is', auc)\n",
    "\n",
    "\n",
    "# Save pipeline model\n",
    "import pickle\n",
    "output_file = f'pipeline_model_C={C}.bin'\n",
    "print(output_file)\n",
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump((training_pipeline), f_out)\n",
    "\n",
    "#load pipeline model\n",
    "import pickle\n",
    "model_file = 'pipeline_model_C=0.5.bin'\n",
    "with open(model_file, 'rb') as f_in:\n",
    "    training_pipeline = pickle.load(f_in)\n",
    "\n",
    "training_pipeline\n",
    "\n",
    "#predict a customer with pipeline\n",
    "test_customer2 = {\n",
    "    'gender': 'male',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'no',\n",
    "    'dependents': 'yes',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbiling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': (1 * 29.85)\n",
    "}\n",
    "\n",
    "churn_proba = training_pipeline.predict_proba(test_customer2)[0,1]\n",
    "print(churn_proba)\n",
    "\n",
    "if churn_proba >= 0.5:\n",
    "    print('send email with promo')\n",
    "else:\n",
    "    print('Do not send promo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24f6f685-329d-4d8a-bc9f-3795af55d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modelling-churn.ipynb to python\n",
      "[NbConvertApp] Writing 6646 bytes to modelling-churn.py\n"
     ]
    }
   ],
   "source": [
    "# convert to script\n",
    "!jupyter nbconvert --to python modelling-churn.ipynb \n",
    "\n",
    "#convert and save as different name -->   !jupyter nbconvert --to python modelling-churn.ipynb --output training.py    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a339bb0-937f-4b93-a8d5-1b6960a4ee84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb9d3e3-bcb4-4261-8609-fc3db9999f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "male      3555\n",
      "female    3488\n",
      "Name: count, dtype: int64\n",
      "seniorcitizen\n",
      "0    5901\n",
      "1    1142\n",
      "Name: count, dtype: int64\n",
      "partner\n",
      "no     3641\n",
      "yes    3402\n",
      "Name: count, dtype: int64\n",
      "dependents\n",
      "no     4933\n",
      "yes    2110\n",
      "Name: count, dtype: int64\n",
      "phoneservice\n",
      "yes    6361\n",
      "no      682\n",
      "Name: count, dtype: int64\n",
      "multiplelines\n",
      "no                  3390\n",
      "yes                 2971\n",
      "no_phone_service     682\n",
      "Name: count, dtype: int64\n",
      "internetservice\n",
      "fiber_optic    3096\n",
      "dsl            2421\n",
      "no             1526\n",
      "Name: count, dtype: int64\n",
      "onlinesecurity\n",
      "no                     3498\n",
      "yes                    2019\n",
      "no_internet_service    1526\n",
      "Name: count, dtype: int64\n",
      "onlinebackup\n",
      "no                     3088\n",
      "yes                    2429\n",
      "no_internet_service    1526\n",
      "Name: count, dtype: int64\n",
      "deviceprotection\n",
      "no                     3095\n",
      "yes                    2422\n",
      "no_internet_service    1526\n",
      "Name: count, dtype: int64\n",
      "techsupport\n",
      "no                     3473\n",
      "yes                    2044\n",
      "no_internet_service    1526\n",
      "Name: count, dtype: int64\n",
      "streamingtv\n",
      "no                     2810\n",
      "yes                    2707\n",
      "no_internet_service    1526\n",
      "Name: count, dtype: int64\n",
      "streamingmovies\n",
      "no                     2785\n",
      "yes                    2732\n",
      "no_internet_service    1526\n",
      "Name: count, dtype: int64\n",
      "contract\n",
      "month-to-month    3875\n",
      "two_year          1695\n",
      "one_year          1473\n",
      "Name: count, dtype: int64\n",
      "paperlessbilling\n",
      "yes    4171\n",
      "no     2872\n",
      "Name: count, dtype: int64\n",
      "paymentmethod\n",
      "electronic_check             2365\n",
      "mailed_check                 1612\n",
      "bank_transfer_(automatic)    1544\n",
      "credit_card_(automatic)      1522\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in categorical:\n",
    "    info = df[c].value_counts()\n",
    "    print(info)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffea7bf7-459c-4a8a-aafa-62aa5f0c747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7043.000000\n",
      "mean       32.371149\n",
      "std        24.559481\n",
      "min         0.000000\n",
      "25%         9.000000\n",
      "50%        29.000000\n",
      "75%        55.000000\n",
      "max        72.000000\n",
      "Name: tenure, dtype: float64\n",
      "count    7043.000000\n",
      "mean       64.761692\n",
      "std        30.090047\n",
      "min        18.250000\n",
      "25%        35.500000\n",
      "50%        70.350000\n",
      "75%        89.850000\n",
      "max       118.750000\n",
      "Name: monthlycharges, dtype: float64\n",
      "count    7043.000000\n",
      "mean     2281.916928\n",
      "std      2265.270398\n",
      "min        18.800000\n",
      "25%       402.225000\n",
      "50%      1397.475000\n",
      "75%      3786.600000\n",
      "max      8684.800000\n",
      "Name: totalcharges, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for n in numerical:\n",
    "    info2 = df[n].describe()\n",
    "    print(info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6eb1e-edbe-4e71-ba09-f7e2bb5f403d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
